# nba-analysis
This project attempts to analyze and visualize NBA statistics on a variety of different levels with the assistance of machine learning in python.
## 2018-2019 Player Stats
The first file that is posted here provides a statistical overview of all the NBA players that suited up in the 2018-2019 NBA season, and it attempted to find any similarities between them. Fist, the data had to be properly retrieved and cleaned, and this was done via the assistance of BeautifulSoup(for retriving the data from the web), and Pandas(for clean/easy organization). Next, a correlation matrix was constructed to see how strongly certain statistics were correlated to other statistics this season. Finally, dimentional reduction and three different methods of data clustering (K-Means, Agglomerative, and Affinity Propagation) were applied to get a better understanding of what other players would be classified as similar to a specific player.
## Bradley Beal Predictions
The second file posted attempts to predict how many points a specific player will put up on a specific night given how well he performed in the previous game and the team he is currently facing. Bladley Beal was selected because he played the more minutes than any other NBA player this season. Once again, data was cleaned and prepared with the assistance of BeautifulSoup and Pandas. The data was then normalized with the Standard Scalar, and correlation matricies were constructed in order to understand what features played the biggest part in predicting points. Next, the seasonally decomposed data was visualized, and autocorrelation charts were constructed with regards to points, rebounds, and assists in order to see if using previous stats would be useful in predicting future stats. These charts surprisingly indicated that historic data wasn't neccesarily an effective predictor of future data. Opponent data was originally deconstructed into dummy variables with the dummy variables reflecting the name of the opposing team, but that strategy was dropped because it would consistently yield poor results. Instead, this opponent data was replaced with an integer that represented how that team placed in the previous year's regular season.

Once all that was completed, different ML algorithms were run on the processed data in an attempt to predict how many points Bradley Beal would score on a specific night. Prediction success was measured and evaluated by looking at the adjusted r^2 and the MSE of the prediction relative to the ground truth on the testing set. A high r^2 and a low MSE is optimal. In order to set some baseline score, linear regression was run. From there, two different methods of regression based prediction were pursued: decision-tree algorithms, and Neural Net models. Extra trees, random forrest, and xgboost were the three algorithms that were used with regards to decision trees, and all of them performed relatively well. This is probably due to the fact that all of the trends and seasonalities seen in the test set were already seen in the training set. For the Neural Net models, Vanilla Feed Forward Neural Networks and LSTM Neural Nets were tested. Although these NN based models didn't produce great metrics, I believe that further tuning the hyperparameters (manually and with talos) and enlarging the dataset will push the NN models to perform better than the trees.
## Historic Player Stats
Even if a really good model was created in regard to a certain player's point prediction, this model wouldn't necesarily translate over and provide great results for every player in the league. There are two real ways to understand and address this issue of scalability. The first way to adress this issue is by running and tuning these forementioned algorithms on every player in the league. That would not be time or resource efficient, so it is best to go ahead and pursue the second method, which is clustur analysis. If it is possible to effectively seperate all the players into n categories, then only n finely tuned models are needed to make effective predictions for everyone in the league. This file and the '2018-2019 Player Stats' file attempt to effectively seperate the players in the league into n clearly defined categories. The only difference is that this file analyzes all the players that have played in the last 20 years (1999-2019) whereas the other file just looks at all of the players this season.
## LeBron James Stat Predictions
One of the potential reasons that the Bradley Beal dataset didn't produce great results was because there simple wasn't a lot of data points contained within it. This file attempts to fix that by looking at how LeBron performed in the first 9 years of his elusive career. A few interesting changes emerged by looking at this larger dataset. First off, all three of the autocorrelation charts showed that there is some sort of significant relationship between the stats that he produces on day n in regard with the stats that he produces on day n-1. All of the models run posted better statistics than the Bradley Beal models, but once again, more hyperparameter tuning is required to make these predictions more viable.
## NBA Analysis
This isn't a critical file to the overall project. This file just details some experimentation with the NBA "all_seasons.csv" file found on Kaggle.

